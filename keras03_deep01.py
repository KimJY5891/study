{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNi8SYIRmgn8wnA1zjDnQMS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M14hMGKFYwN0","executionInfo":{"status":"ok","timestamp":1677678463248,"user_tz":-540,"elapsed":17207,"user":{"displayName":"김지윤","userId":"13231425941624548243"}},"outputId":"09fdc192-f3e1-475f-d2d8-52863964a683"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 4s 4s/step - loss: 0.1642\n","Epoch 2/100\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0010\n","Epoch 3/100\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0818\n","Epoch 4/100\n","1/1 [==============================] - 0s 21ms/step - loss: 0.0932\n","Epoch 5/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0403\n","Epoch 6/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0022\n","Epoch 7/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0111\n","Epoch 8/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0398\n","Epoch 9/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0462\n","Epoch 10/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0270\n","Epoch 11/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0057\n","Epoch 12/100\n","1/1 [==============================] - 0s 16ms/step - loss: 7.1911e-04\n","Epoch 13/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0112\n","Epoch 14/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0225\n","Epoch 15/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0231\n","Epoch 16/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0137\n","Epoch 17/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0033\n","Epoch 18/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.0519e-04\n","Epoch 19/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0051\n","Epoch 20/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0114\n","Epoch 21/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0124\n","Epoch 22/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0076\n","Epoch 23/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0019\n","Epoch 24/100\n","1/1 [==============================] - 0s 21ms/step - loss: 1.0917e-04\n","Epoch 25/100\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0027\n","Epoch 26/100\n","1/1 [==============================] - 0s 20ms/step - loss: 0.0061\n","Epoch 27/100\n","1/1 [==============================] - 0s 27ms/step - loss: 0.0068\n","Epoch 28/100\n","1/1 [==============================] - 0s 24ms/step - loss: 0.0042\n","Epoch 29/100\n","1/1 [==============================] - 0s 25ms/step - loss: 0.0011\n","Epoch 30/100\n","1/1 [==============================] - 0s 19ms/step - loss: 5.2130e-05\n","Epoch 31/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0015\n","Epoch 32/100\n","1/1 [==============================] - 0s 27ms/step - loss: 0.0035\n","Epoch 33/100\n","1/1 [==============================] - 0s 20ms/step - loss: 0.0037\n","Epoch 34/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0021\n","Epoch 35/100\n","1/1 [==============================] - 0s 17ms/step - loss: 3.6885e-04\n","Epoch 36/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.1362e-04\n","Epoch 37/100\n","1/1 [==============================] - 0s 21ms/step - loss: 0.0011\n","Epoch 38/100\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0021\n","Epoch 39/100\n","1/1 [==============================] - 0s 21ms/step - loss: 0.0019\n","Epoch 40/100\n","1/1 [==============================] - 0s 20ms/step - loss: 8.4608e-04\n","Epoch 41/100\n","1/1 [==============================] - 0s 21ms/step - loss: 5.9037e-05\n","Epoch 42/100\n","1/1 [==============================] - 0s 19ms/step - loss: 2.1073e-04\n","Epoch 43/100\n","1/1 [==============================] - 0s 18ms/step - loss: 9.0349e-04\n","Epoch 44/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0012\n","Epoch 45/100\n","1/1 [==============================] - 0s 16ms/step - loss: 8.3875e-04\n","Epoch 46/100\n","1/1 [==============================] - 0s 16ms/step - loss: 2.0880e-04\n","Epoch 47/100\n","1/1 [==============================] - 0s 18ms/step - loss: 1.1209e-05\n","Epoch 48/100\n","1/1 [==============================] - 0s 23ms/step - loss: 3.3246e-04\n","Epoch 49/100\n","1/1 [==============================] - 0s 21ms/step - loss: 6.8135e-04\n","Epoch 50/100\n","1/1 [==============================] - 0s 13ms/step - loss: 6.2509e-04\n","Epoch 51/100\n","1/1 [==============================] - 0s 20ms/step - loss: 2.5681e-04\n","Epoch 52/100\n","1/1 [==============================] - 0s 20ms/step - loss: 7.2727e-06\n","Epoch 53/100\n","1/1 [==============================] - 0s 18ms/step - loss: 1.0680e-04\n","Epoch 54/100\n","1/1 [==============================] - 0s 18ms/step - loss: 3.5144e-04\n","Epoch 55/100\n","1/1 [==============================] - 0s 16ms/step - loss: 4.0461e-04\n","Epoch 56/100\n","1/1 [==============================] - 0s 17ms/step - loss: 2.1222e-04\n","Epoch 57/100\n","1/1 [==============================] - 0s 19ms/step - loss: 2.1067e-05\n","Epoch 58/100\n","1/1 [==============================] - 0s 18ms/step - loss: 3.6319e-05\n","Epoch 59/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.8430e-04\n","Epoch 60/100\n","1/1 [==============================] - 0s 22ms/step - loss: 2.4739e-04\n","Epoch 61/100\n","1/1 [==============================] - 0s 19ms/step - loss: 1.4888e-04\n","Epoch 62/100\n","1/1 [==============================] - 0s 20ms/step - loss: 2.2229e-05\n","Epoch 63/100\n","1/1 [==============================] - 0s 19ms/step - loss: 1.4417e-05\n","Epoch 64/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.0260e-04\n","Epoch 65/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.4927e-04\n","Epoch 66/100\n","1/1 [==============================] - 0s 15ms/step - loss: 9.3205e-05\n","Epoch 67/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.4438e-05\n","Epoch 68/100\n","1/1 [==============================] - 0s 13ms/step - loss: 8.8768e-06\n","Epoch 69/100\n","1/1 [==============================] - 0s 21ms/step - loss: 6.3139e-05\n","Epoch 70/100\n","1/1 [==============================] - 0s 12ms/step - loss: 9.0183e-05\n","Epoch 71/100\n","1/1 [==============================] - 0s 16ms/step - loss: 5.3764e-05\n","Epoch 72/100\n","1/1 [==============================] - 0s 16ms/step - loss: 6.8341e-06\n","Epoch 73/100\n","1/1 [==============================] - 0s 20ms/step - loss: 7.6007e-06\n","Epoch 74/100\n","1/1 [==============================] - 0s 24ms/step - loss: 4.2013e-05\n","Epoch 75/100\n","1/1 [==============================] - 0s 23ms/step - loss: 5.4154e-05\n","Epoch 76/100\n","1/1 [==============================] - 0s 14ms/step - loss: 2.7873e-05\n","Epoch 77/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.8657e-06\n","Epoch 78/100\n","1/1 [==============================] - 0s 19ms/step - loss: 8.0290e-06\n","Epoch 79/100\n","1/1 [==============================] - 0s 27ms/step - loss: 2.9333e-05\n","Epoch 80/100\n","1/1 [==============================] - 0s 13ms/step - loss: 3.1345e-05\n","Epoch 81/100\n","1/1 [==============================] - 0s 16ms/step - loss: 1.2363e-05\n","Epoch 82/100\n","1/1 [==============================] - 0s 15ms/step - loss: 1.5041e-07\n","Epoch 83/100\n","1/1 [==============================] - 0s 18ms/step - loss: 8.4963e-06\n","Epoch 84/100\n","1/1 [==============================] - 0s 21ms/step - loss: 2.0260e-05\n","Epoch 85/100\n","1/1 [==============================] - 0s 18ms/step - loss: 1.6641e-05\n","Epoch 86/100\n","1/1 [==============================] - 0s 11ms/step - loss: 4.0237e-06\n","Epoch 87/100\n","1/1 [==============================] - 0s 19ms/step - loss: 5.9817e-07\n","Epoch 88/100\n","1/1 [==============================] - 0s 17ms/step - loss: 8.3720e-06\n","Epoch 89/100\n","1/1 [==============================] - 0s 22ms/step - loss: 1.3063e-05\n","Epoch 90/100\n","1/1 [==============================] - 0s 16ms/step - loss: 7.4510e-06\n","Epoch 91/100\n","1/1 [==============================] - 0s 16ms/step - loss: 5.9649e-07\n","Epoch 92/100\n","1/1 [==============================] - 0s 22ms/step - loss: 1.8751e-06\n","Epoch 93/100\n","1/1 [==============================] - 0s 14ms/step - loss: 7.1929e-06\n","Epoch 94/100\n","1/1 [==============================] - 0s 20ms/step - loss: 7.3059e-06\n","Epoch 95/100\n","1/1 [==============================] - 0s 10ms/step - loss: 2.3570e-06\n","Epoch 96/100\n","1/1 [==============================] - 0s 16ms/step - loss: 5.1835e-08\n","Epoch 97/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.8391e-06\n","Epoch 98/100\n","1/1 [==============================] - 0s 16ms/step - loss: 5.1537e-06\n","Epoch 99/100\n","1/1 [==============================] - 0s 17ms/step - loss: 3.1692e-06\n","Epoch 100/100\n","1/1 [==============================] - 0s 15ms/step - loss: 2.8691e-07\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8ee830f430>"]},"metadata":{},"execution_count":1}],"source":["#1.데이터\n","import numpy as np\n","#사람이 생각하듯 계산한다.\n","x = np.array([1,2,3])\n","y = np.array([1,2,3])\n","\n","#2. 모델\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","#신경망이 밑으로 순차적으로 연산(Sequential)\n","from tensorflow.keras.layers import Dense\n","\n","model=Sequential()\n","#우리는 Sequential 모델을 사용할 거야\n","#Sequential를 모델이라 정의할 것이다.\n","model.add(Dense(3,input_dim=1))\n","#input_dim = 최초의 인풋 1개\n","model.add(Dense(7))\n","model.add(Dense(12))\n","model.add(Dense(18))\n","#중앙은 어떻게 될지 몰라서 hidden 레이어\n","#성능ㄴ 레이어 값을 보는게 아니라 결과를 보고 판단하는 것이다.\n","model.add(Dense(22))\n","model.add(Dense(25))\n","model.add(Dense(18))\n","model.add(Dense(10))\n","model.add(Dense(1))\n","#output layer\n","#안에 내용이나 수치를 바꾸는 튜을 튜닝한다고 한다.\n","\n","#3. 컴파일, 훈련\n","#컴파일이란? 기계어로 바꾼다.\n","#기계야 내가 한 소스를가 네가 알아들어라~\n","model.compile(loss='mse',optimizer='adam')\n","#평균제곱오차(mse)는 n개의 데이터에오대해 오차의 제곱의 평균으로 정의합니다.\n","#제곱값으로 나눠도제괜찮은 것이 어차피 로스 값은 상대적 비교이기 때에에 상관없다.\n","#optimizer=최적화\n","#optimizer = adam은 평타, 한 85%정도 성능나옴\n","model.fit(x,y,epochs=100)\n","#- loss: 2.8691e-07\n","\n"]}]}