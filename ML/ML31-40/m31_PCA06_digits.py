### 실습 ### 
#for문 써서 한 번에 돌리기
# 기본 결과 : 
# 차원 1개 축소 :
# 차원 2개 축소 : 
 
import numpy as np
import pandas as pd
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

# 1. 데이터 
datasets = load_digits()
x = datasets['data']
y = datasets['target']
print(x.shape,y.shape) #(442, 10) (442,)
x_train, x_test,y_train,y_test = train_test_split(
    x,y , train_size=0.8,random_state=123, shuffle=True,
)
# 2. 모델 
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(random_state=123)
# 3. 훈련 
model.fit(x_train,y_train)
# 4. 평가, 예측
results = model.score(x_test,y_test)
print("처음 결과 : ", results)
print(len(x[0]))
for i in range(x.shape[1]):
    #print('i 값 : ',i)
    # 1. 데이터 
    datasets = load_digits()
    x = datasets['data']
    y = datasets['target']
    pca = PCA(n_components=(i+1))
    x = pca.fit_transform(x)
    x_train, x_test,y_train,y_test = train_test_split(
        x,y , train_size=0.8,random_state=123, shuffle=True,
    )
    # 2. 모델 
    from sklearn.ensemble import RandomForestRegressor
    model = RandomForestRegressor(random_state=123)
    # 3. 훈련 
    model.fit(x_train,y_train)
    # 4. 평가, 예측
    results = model.score(x_test,y_test)
    print(i+1,"차원 결과 : ", results)
'''
처음 결과 :  0.8341701582929435
64
1 차원 결과 :  -0.48619311209400484
2 차원 결과 :  0.39008914903196756
3 차원 결과 :  0.6199968570949317
4 차원 결과 :  0.6724708707436149
5 차원 결과 :  0.7421507358458916
6 차원 결과 :  0.7495690512134616
7 차원 결과 :  0.8113602952211951
8 차원 결과 :  0.7939615965251476
9 차원 결과 :  0.814897935040743
10 차원 결과 :  0.8166117364550503
11 차원 결과 :  0.8216408083269328
12 차원 결과 :  0.8252907805175199
13 차원 결과 :  0.823733206204589
14 차원 결과 :  0.8225517210936604
15 차원 결과 :  0.8195108368426164
16 차원 결과 :  0.822655154452596
17 차원 결과 :  0.8251472309770373
18 차원 결과 :  0.8141701936064836
19 차원 결과 :  0.8147118679979871
20 차원 결과 :  0.8142483424707119
21 차원 결과 :  0.8150403192344025
22 차원 결과 :  0.8074634460718101
23 차원 결과 :  0.8104939481420663
24 차원 결과 :  0.8115329431187153
25 차원 결과 :  0.8115816404905052
26 차원 결과 :  0.805784993511137
27 차원 결과 :  0.8036846147734195
28 차원 결과 :  0.8037625164428671
29 차원 결과 :  0.8012191999717492
30 차원 결과 :  0.8001912228196096
31 차원 결과 :  0.7983364850667868
32 차원 결과 :  0.7988856812423304
33 차원 결과 :  0.7984522781647554
34 차원 결과 :  0.799204103433359
35 차원 결과 :  0.7983670312789681
36 차원 결과 :  0.7907432617351308
37 차원 결과 :  0.78601124736252
38 차원 결과 :  0.7891990006268154
39 차원 결과 :  0.7850559454758941
40 차원 결과 :  0.7834148546406405
41 차원 결과 :  0.7826213947082661
42 차원 결과 :  0.7876267358812052
43 차원 결과 :  0.7882129406467675
44 차원 결과 :  0.7856459994173266
45 차원 결과 :  0.780510704416841
46 차원 결과 :  0.7834758764379233
47 차원 결과 :  0.7863338012377397
48 차원 결과 :  0.7854424874857642
49 차원 결과 :  0.7869966716988461
50 차원 결과 :  0.7826212181405655
51 차원 결과 :  0.7843362908423163
52 차원 결과 :  0.7825230818126441
53 차원 결과 :  0.7819365239116809
54 차원 결과 :  0.7830929364091427
55 차원 결과 :  0.7866179339813368
56 차원 결과 :  0.7850743791438233
57 차원 결과 :  0.7799246055918991
58 차원 결과 :  0.7834785249534303
59 차원 결과 :  0.7815468743102824
60 차원 결과 :  0.7804417723865773
61 차원 결과 :  0.7830082898535371
62 차원 결과 :  0.7825229052449436
63 차원 결과 :  0.7808869348730036
64 차원 결과 :  0.7812653547686522
'''
