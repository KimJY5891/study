{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd(자동미분)\n",
        "*   torch.autograd 패키지는 Tensor의 모든 연산에 대해 자동 미분 제공\n",
        "*   이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻  \n",
        "*   backprop를 위해 미분값을 자동으로 계산\n",
        "\n",
        "requires_grad 속성을 True로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추척하기 시작\n",
        "\n",
        "기록을 추척하는 것을 중단하게 하려면, .detach()를 호출하여 연산 기록으로부터 분리\n"
      ],
      "metadata": {
        "id": "2oB3vfuYxD_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.randn(3,3)\n",
        "a = a *3\n",
        "print(a)\n",
        "print(a.requires_grad) # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcSI5KgS0ojW",
        "outputId": "d1de1428-3537-4a22-fafb-17d080e58501"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8107,  0.9547,  2.0495],\n",
            "        [ 2.4820,  1.4881,  5.4323],\n",
            "        [-4.6738, -0.1096,  1.2293]])\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires_grad_(...)는 기존 텐서의 requires_grad 값을 바꿔치기(in-place)하여 변경\n",
        "\n",
        "grad_fn: 미분 값을 계산한 함수에 대한 정보 저장( 어떤 함수에 대해서 backprop 했는지):"
      ],
      "metadata": {
        "id": "r_1fKJ341BfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a*a)\n",
        "print(b)\n",
        "b = (a*a).sum()\n",
        "print(b) # 모든 값을 더한것\n",
        "print(b.grad_fn) # 모든 값을 더한것\n",
        "# tensor(96.2691, grad_fn=<SumBackward0>) -> 이렇게 기록으로 남기는 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlezNelxxFlU",
        "outputId": "c03aff54-ff4e-453b-b0c6-415a228e560f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "tensor([[6.5728e-01, 9.1136e-01, 4.2004e+00],\n",
            "        [6.1605e+00, 2.2144e+00, 2.9510e+01],\n",
            "        [2.1845e+01, 1.2004e-02, 1.5111e+00]], grad_fn=<MulBackward0>)\n",
            "tensor(67.0215, grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7e7efca73a60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기울기(Gradient)"
      ],
      "metadata": {
        "id": "wVHrq6VE0f48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3,3,requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsm2hw0f0fHf",
        "outputId": "e37970f7-b07f-477f-f817-e3ea33e0df2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x +5\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T5QMpYwOEJr",
        "outputId": "17d24084-59eb-4dfd-b99d-0b8dbf5c28ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=y*y\n",
        "out = z.mean()\n",
        "print(z,out)\n",
        "# MulBackward0 # 곱에 대한 그래디언트 저장\n",
        "# Mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoV64O1SOSLi",
        "outputId": "e13d1e74-c3e0-4c50-efd0-dbe754333f51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[36., 36., 36.],\n",
            "        [36., 36., 36.],\n",
            "        [36., 36., 36.]], grad_fn=<MulBackward0>) tensor(36., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산이 완료된 후, backward()를 호출하면 자동으로 역전파 계산이 가능하고, .grad 속성에 누적됌"
      ],
      "metadata": {
        "id": "Gwi4jCRpPETr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(out) # 호출\n",
        "out.backward()\n",
        "# backward() 메서드를 호출하면,\n",
        "# PyTorch는 미적분학의 연쇄 법칙을 사용하여 기울기를 계산하기 위해\n",
        "# 이 그래프를 역순으로 (출력에서 입력까지) 순회합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mg-df1PPDa1",
        "outputId": "aa357bc7-8e73-4dcf-b279-5a2e5c0c306b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad : data가 거쳐온 layer에 대한 미분값 저장"
      ],
      "metadata": {
        "id": "BLvzeCB0QpON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(x.grad) # 미분 값이 몇인지 알려줘"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciQk0acPPl_v",
        "outputId": "702c0bf5-1787-4428-b73f-337adc08a6af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n",
            "tensor([[1.3333, 1.3333, 1.3333],\n",
            "        [1.3333, 1.3333, 1.3333],\n",
            "        [1.3333, 1.3333, 1.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3,requires_grad=True)\n",
        "y = x *2\n",
        "while y.data.norm()<1000 : # 노멀라이제이션 1000이하라면\n",
        "  y = y*2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLk3nR8FRBMI",
        "outputId": "7f13a8f3-1078-42ff-a064-6b184170c1e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1132.2120,   797.5872,  -964.3265], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([0.1,1.0,0.0001],dtype=torch.float) # 외부 그래디언트\n",
        "y.backward(v) # v를 기준으로 백워드가 된다.\n",
        "print(x.grad) # 그래디언트"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBw23zTvRoAK",
        "outputId": "6eb12dd0-1355-4222-e45e-53d100630f3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# with torch.no_grad()\n",
        "with torch.no_grad()를 사용하여 기울기의 업데이트를 하지 않음\n",
        "\n",
        "기록을 추척하는 것을 방지하기 위해 코드 블랙을 with torch.no_Grad()로 감싸면 기울기 계산은 필요 없지만,\n",
        "\n",
        " requires_grad =True로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용"
      ],
      "metadata": {
        "id": "gLeInjK-Rnbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가할 때만 사용\n",
        "print(x.requires_grad)\n",
        "print((x**2).requires_grad)\n",
        "\n",
        "with torch.no_grad() : # 기울기 업데이트를 하지 말아줘\n",
        "  print((x**2).requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99WoQ_8IU7tw",
        "outputId": "25aa44ee-ce2c-4e21-8e14-c12b45ea2ec8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "detach() : 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올때"
      ],
      "metadata": {
        "id": "gmCqprQIPXKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "detach() 메서드는 PyTorch의 텐서에서 매우 중요한 기능을 수행합니다.\n",
        "이 메서드를 사용하여 텐서를 원래의 계산 그래프에서 \"분리\"할 수 있습니다.\n",
        "\n",
        "detach()에 대한 주요 사항\n",
        "\n",
        "분리된 텐서 생성: detach() 메서드는 원본 텐서와 동일한 데이터를 가지지만,\n",
        "계산 그래프에서 분리된 새 텐서를 반환합니다.\n",
        "\n",
        "기울기 추적 비활성화: detach()로 생성된 텐서는 기울기 계산에서 제외됩니다.\n",
        "즉, 분리된 텐서의 requires_grad 속성은 False로 설정됩니다.\n",
        "\n",
        "메모리 공유: 원본 텐서와 detach()로 생성된 텐서는 동일한 메모리를 공유합니다.\n",
        "따라서, 하나의 텐서의 값을 변경하면 다른 텐서의 값도 변경됩니다.\n",
        "\n",
        "모델 평가 및 변환: detach()는 주로 모델을 평가할 때나 텐서 값을 numpy 배열로 변환할 때 사용됩니다.\n",
        "이러한 경우에는 기울기를 계산할 필요가 없기 때문에 텐서를 계산 그래프에서 분리하여 기울기 계산을 방지합니다.\n",
        "즉 미분 안하게 하기 위해서 그냥 값만 쓰윽 빼온것\n",
        "'''\n",
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all()) # y와 x가 같은지 모두 계싼\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4fBEB8V-bRy",
        "outputId": "7329dc14-8505-476f-c454-468bc90d6229"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ]
    }
  ]
}